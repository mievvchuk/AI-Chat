# ai_groq_chat_full.py

import os
import asyncio
import re

from groq import Groq
from aiogram import Bot, Dispatcher, types
from aiogram.filters import CommandStart
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton


# ===========================
# üîë –¢–í–û–á –¢–û–ö–ï–ù–ò (ENV —É Railway)
# ===========================
TOKEN = os.getenv("TOKEN")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not TOKEN or not GROQ_API_KEY:
    raise RuntimeError("–ù–µ –∑–∞–¥–∞–Ω—ñ –∑–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞ TOKEN –∞–±–æ GROQ_API_KEY")

client = Groq(api_key=GROQ_API_KEY)
bot = Bot(token=TOKEN)
dp = Dispatcher(storage=MemoryStorage())


# ===========================
# ‚öôÔ∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π —Ç–∞ —Ä–µ–∂–∏–º—ñ–≤
# ===========================
MODELS = {
    "8B": "llama-3.1-8b-instant",
    "70B": "llama-3.1-70b-versatile",
    "SCOUT": "meta-llama/llama-4-scout-17b-16e-instruct",
}
MODEL_ORDER = ["8B", "70B", "SCOUT"]
DEFAULT_MODEL_KEY = "SCOUT"

ANSWER_MODES = {
    "short": "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –¥—É–∂–µ –∫–æ—Ä–æ—Ç–∫–æ, 1‚Äì3 —Ä–µ—á–µ–Ω–Ω—è.",
    "deep": "–î–∞–≤–∞–π –¥–µ—Ç–∞–ª—å–Ω—É, –∞–ª–µ –∑—Ä–æ–∑—É–º—ñ–ª—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑ –ø—Ä–∏–∫–ª–∞–¥–∞–º–∏.",
    "expert": "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —è–∫ senior-—Ä–æ–∑—Ä–æ–±–Ω–∏–∫, —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–æ –π —Ç–µ—Ö–Ω—ñ—á–Ω–æ.",
}
ANSWER_ORDER = ["short", "deep", "expert"]
DEFAULT_ANSWER_MODE = "deep"


# ===========================
# üß† –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º–æ–≤–∏ –∫–æ–¥—É
# ===========================
def detect_language(text: str) -> str:
    t = text.lower()
    if "#include" in t or "std::" in t or "int main" in t:
        return "cpp"
    if "def " in t or "class " in t or "print(" in t:
        return "python"
    if "<html" in t or "<div" in t or "<body" in t:
        return "html"
    if "function " in t or "console.log" in t or " => " in t:
        return "javascript"
    return "text"


# ===========================
# üì¶ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –æ–≥–æ—Ä—Ç–∞–Ω–Ω—è –≤—Å—å–æ–≥–æ —Ç–µ–∫—Å—Ç—É –≤ ```–∫–æ–¥``` (—è–∫—â–æ —Ü–µ —Å—Ö–æ–∂–µ –Ω–∞ –∫–æ–¥)
# ===========================
def wrap_code_blocks(text: str) -> str:
    if "```" in text:
        return text

    lines = text.strip().split("\n")
    if len(lines) < 2:
        return text

    suspicious = sum(
        any(sym in line for sym in (";", "(", ")", "{", "}", "=", "<", ">"))
        for line in lines
    )

    if suspicious >= 2:
        lang = detect_language(text)
        return f"```{lang}\n{text}\n```"

    return text


# ===========================
# üß© –î—ñ—Å—Ç–∞–≤–∞–Ω–Ω—è –∫–æ–¥–æ–≤–∏—Ö –±–ª–æ–∫—ñ–≤ –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
# ===========================
CODE_BLOCK_RE = re.compile(r"```(?:\w+)?\n(.*?)```", re.DOTALL)


def extract_code_blocks(text: str):
    return CODE_BLOCK_RE.findall(text)


# ===========================
# FSM
# ===========================
class Chat(StatesGroup):
    chatting = State()


# ===========================
# –ö–ª–∞–≤—ñ–∞—Ç—É—Ä–∞ –º–µ–Ω—é
# ===========================
main_menu = ReplyKeyboardMarkup(
    keyboard=[
        [KeyboardButton(text="üÜï –ù–æ–≤–∏–π —á–∞—Ç"), KeyboardButton(text="üí° –ü—Ä–∏–∫–ª–∞–¥–∏")],
        [KeyboardButton(text="üîÑ –ó–º—ñ–Ω–∏—Ç–∏ –º–æ–¥–µ–ª—å"), KeyboardButton(text="üß† –†–µ–∂–∏–º –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ")],
        [KeyboardButton(text="üõ† –ü–æ—è—Å–Ω–∏ –∫–æ–¥"), KeyboardButton(text="üé® –ü–µ—Ä–µ—Ñ–æ—Ä–º–∞—Ç—É–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å")],
        [KeyboardButton(text="üì¶ –ö–æ–¥ —É –±–ª–æ—Ü—ñ ON/OFF"), KeyboardButton(text="‚ÑπÔ∏è –ü—Ä–æ –±–æ—Ç–∞")],
    ],
    resize_keyboard=True,
)


# ===========================
# /start
# ===========================
@dp.message(CommandStart())
async def start(m: types.Message, state: FSMContext):
    await state.set_state(Chat.chatting)
    await state.set_data(
        {
            "history": [],
            "model_key": DEFAULT_MODEL_KEY,
            "answer_mode": DEFAULT_ANSWER_MODE,
            "wrap_code": True,
            "awaiting_code_explain": False,
            "last_reply": "",
            "last_code_blocks": [],
        }
    )

    await m.answer(
        "–ü—Ä–∏–≤—ñ—Ç! –Ø ‚Äî AI-—á–∞—Ç –Ω–∞ Groq (Llama-4 Scout).\n"
        "–û–±–µ—Ä–∏ –¥—ñ—é –≤ –º–µ–Ω—é –∞–±–æ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —Å–≤—ñ–π –∑–∞–ø–∏—Ç.",
        reply_markup=main_menu,
    )


# ===========================
# üÜï –ù–æ–≤–∏–π —á–∞—Ç
# ===========================
@dp.message(lambda m: m.text == "üÜï –ù–æ–≤–∏–π —á–∞—Ç")
async def menu_new(m: types.Message, state: FSMContext):
    data = await state.get_data()
    await state.set_data(
        {
            "history": [],
            "model_key": data.get("model_key", DEFAULT_MODEL_KEY),
            "answer_mode": data.get("answer_mode", DEFAULT_ANSWER_MODE),
            "wrap_code": data.get("wrap_code", True),
            "awaiting_code_explain": False,
            "last_reply": "",
            "last_code_blocks": [],
        }
    )
    await m.answer("–ß–∞—Ç –æ—á–∏—â–µ–Ω–æ.")


# ===========================
# üí° –ü—Ä–∏–∫–ª–∞–¥–∏
# ===========================
@dp.message(lambda m: m.text == "üí° –ü—Ä–∏–∫–ª–∞–¥–∏")
async def menu_examples(m: types.Message):
    text = (
        "–û—Å—å –¥–µ–∫—ñ–ª—å–∫–∞ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ –∑–∞–ø–∏—Ç—ñ–≤:\n\n"
        "1. –ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü—ñ—é C++ –¥–ª—è —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –º–∞—Å–∏–≤—É –≤—Å—Ç–∞–≤–∫–∞–º–∏.\n"
        "2. –ü–æ—è—Å–Ω–∏, —â–æ —Ç–∞–∫–µ SOLID –ø—Ä–æ—Å—Ç–∏–º–∏ —Å–ª–æ–≤–∞–º–∏.\n"
        "3. –ó—Ä–æ–±–∏ SQL-–∑–∞–ø–∏—Ç –∑ JOIN –¥–ª—è –≤–∏–±—ñ—Ä–∫–∏ –∑–∞–º–æ–≤–ª–µ–Ω—å —ñ –∫–ª—ñ—î–Ω—Ç—ñ–≤.\n"
        "4. –ó–Ω–∞–π–¥–∏ –ø–æ–º–∏–ª–∫—É –≤ —Ü—å–æ–º—É –∫–æ–¥—ñ Python —ñ –≤–∏–ø—Ä–∞–≤.\n"
        "5. –ó–≥–µ–Ω–µ—Ä—É–π HTML-—à–∞–±–ª–æ–Ω –æ–¥–Ω–æ—Å—Ç–æ—Ä—ñ–Ω–∫–æ–≤–æ–≥–æ —Å–∞–π—Ç—É.\n"
        "6. –î–æ–ø–æ–º–æ–∂–∏ —Ä–æ–∑–≤ º—è–∑–∞—Ç–∏ –∑–∞–¥–∞—á—É –∑ —Ç–µ–æ—Ä—ñ—ó –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π.\n"
    )
    await m.answer(text)


# ===========================
# üîÑ –ó–º—ñ–Ω–∞ –º–æ–¥–µ–ª—ñ
# ===========================
@dp.message(lambda m: m.text == "üîÑ –ó–º—ñ–Ω–∏—Ç–∏ –º–æ–¥–µ–ª—å")
async def menu_change_model(m: types.Message, state: FSMContext):
    data = await state.get_data()
    current = data.get("model_key", DEFAULT_MODEL_KEY)

    idx = MODEL_ORDER.index(current) if current in MODEL_ORDER else 0
    new_key = MODEL_ORDER[(idx + 1) % len(MODEL_ORDER)]

    await state.update_data(model_key=new_key)
    await m.answer(f"–û–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {new_key} ‚Üí `{MODELS[new_key]}`")


# ===========================
# üß† –†–µ–∂–∏–º –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
# ===========================
@dp.message(lambda m: m.text == "üß† –†–µ–∂–∏–º –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ")
async def menu_answer_mode(m: types.Message, state: FSMContext):
    data = await state.get_data()
    current = data.get("answer_mode", DEFAULT_ANSWER_MODE)

    idx = ANSWER_ORDER.index(current) if current in ANSWER_ORDER else 0
    new_mode = ANSWER_ORDER[(idx + 1) % len(ANSWER_ORDER)]

    await state.update_data(answer_mode=new_mode)
    desc = ANSWER_MODES[new_mode]
    await m.answer(f"–†–µ–∂–∏–º –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {new_mode.upper()}\n{desc}")


# ===========================
# üì¶ –ö–æ–¥ —É –±–ª–æ—Ü—ñ ON/OFF
# ===========================
@dp.message(lambda m: m.text == "üì¶ –ö–æ–¥ —É –±–ª–æ—Ü—ñ ON/OFF")
async def menu_code_wrap(m: types.Message, state: FSMContext):
    data = await state.get_data()
    new_val = not data.get("wrap_code", True)
    await state.update_data(wrap_code=new_val)
    status = "–£–í–Ü–ú–ö–ù–ï–ù–û" if new_val else "–í–ò–ú–ö–ù–ï–ù–û"
    await m.answer(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—è –≤—Å—å–æ–≥–æ —Ç–µ–∫—Å—Ç—É —è–∫ –∫–æ–¥–æ–≤–æ–≥–æ –±–ª–æ–∫—É: {status}")


# ===========================
# ‚ÑπÔ∏è –ü—Ä–æ –±–æ—Ç–∞
# ===========================
@dp.message(lambda m: m.text == "‚ÑπÔ∏è –ü—Ä–æ –±–æ—Ç–∞")
async def menu_about(m: types.Message, state: FSMContext):
    data = await state.get_data()
    model_key = data.get("model_key", DEFAULT_MODEL_KEY)
    answer_mode = data.get("answer_mode", DEFAULT_ANSWER_MODE)

    await m.answer(
        "ü§ñ AI-Chat Bot\n"
        f"üß† –ú–æ–¥–µ–ª—å: {model_key} ‚Üí {MODELS[model_key]}\n"
        f"üìè –†–µ–∂–∏–º –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {answer_mode}\n"
        "‚öô –ü—Ä–∞—Ü—é—î —á–µ—Ä–µ–∑ Groq API + aiogram.\n"
    )


# ===========================
# üõ† –ü–æ—è—Å–Ω–∏ –∫–æ–¥
# ===========================
@dp.message(lambda m: m.text == "üõ† –ü–æ—è—Å–Ω–∏ –∫–æ–¥")
async def menu_explain_code(m: types.Message, state: FSMContext):
    data = await state.get_data()
    blocks = data.get("last_code_blocks") or []

    if blocks:
        # –±–µ—Ä–µ–º–æ –Ω–∞–π–±—ñ–ª—å—à–∏–π –∫–æ–¥–æ–≤–∏–π –±–ª–æ–∫ –∑ –æ—Å—Ç–∞–Ω–Ω—å–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
        code = max(blocks, key=len)
        await _explain_code_internal(m, state, code)
    else:
        # –Ω–µ–º–∞—î –∑–±–µ—Ä–µ–∂–µ–Ω–æ–≥–æ –∫–æ–¥—É ‚Äî –ø—Ä–æ—Å–∏–º–æ –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏
        await state.update_data(awaiting_code_explain=True)
        await m.answer("–ù–∞–¥—ñ—à–ª–∏ –∫–æ–¥, —è–∫–∏–π –ø–æ—Ç—Ä—ñ–±–Ω–æ –ø–æ—è—Å–Ω–∏—Ç–∏.")


async def _explain_code_internal(m: types.Message, state: FSMContext, code: str):
    data = await state.get_data()
    model_key = data.get("model_key", DEFAULT_MODEL_KEY)

    system_prompt = (
        "–¢–∏ –ø–æ—è—Å–Ω—é—î—à –∫–æ–¥ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é.\n"
        "–î–∞–π –ø–æ–∫—Ä–æ–∫–æ–≤–∏–π —Ä–æ–∑–±—ñ—Ä, —â–æ —Ä–æ–±–∏—Ç—å –∫–æ–¥, –≤–∞–∂–ª–∏–≤—ñ –º–æ–º–µ–Ω—Ç–∏ —Ç–∞ –º–æ–∂–ª–∏–≤—ñ –ø–æ–º–∏–ª–∫–∏."
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"–ü–æ—è—Å–Ω–∏ —Ü–µ–π –∫–æ–¥:\n```text\n{code}\n```"},
    ]

    def _call():
        return client.chat.completions.create(
            model=MODELS[model_key],
            messages=messages,
            temperature=0.4,
            max_completion_tokens=1024,
            top_p=1,
        )

    await bot.send_chat_action(m.chat.id, "typing")
    resp = await asyncio.to_thread(_call)
    reply = resp.choices[0].message.content

    await m.answer(reply)

    # –æ–Ω–æ–≤–∏–º–æ –æ—Å—Ç–∞–Ω–Ω—é –≤—ñ–¥–ø–æ–≤—ñ–¥—å / –∫–æ–¥
    blocks = extract_code_blocks(reply)
    await state.update_data(last_reply=reply, last_code_blocks=blocks)


# ===========================
# üé® –ü–µ—Ä–µ—Ñ–æ—Ä–º–∞—Ç—É–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
# ===========================
@dp.message(lambda m: m.text == "üé® –ü–µ—Ä–µ—Ñ–æ—Ä–º–∞—Ç—É–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å")
async def menu_reformat_answer(m: types.Message, state: FSMContext):
    data = await state.get_data()
    last_reply = data.get("last_reply", "")

    if not last_reply:
        await m.answer("–ü–æ–∫–∏ —â–æ –Ω–µ–º–∞—î –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ, —è–∫—É –º–æ–∂–Ω–∞ –ø–µ—Ä–µ—Ñ–æ—Ä–º–∞—Ç—É–≤–∞—Ç–∏.")
        return

    model_key = data.get("model_key", DEFAULT_MODEL_KEY)

    system_prompt = (
        "–¢–∏ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–ª—å–Ω–∏–∫ —Ç–µ–∫—Å—Ç—É.\n"
        "–ü–µ—Ä–µ–ø–∏—à–∏ –Ω–∞—Å—Ç—É–ø–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –±—ñ–ª—å—à —á–∏—Ç–∞–±–µ–ª—å–Ω–æ: –∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏, —Å–ø–∏—Å–∫–∞–º–∏, "
        "—á—ñ—Ç–∫–∏–º–∏ –±–ª–æ–∫–∞–º–∏, –∞–ª–µ –±–µ–∑ –≤–∏–≥–∞–¥—É–≤–∞–Ω–Ω—è –Ω–æ–≤–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó."
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": last_reply},
    ]

    def _call():
        return client.chat.completions.create(
            model=MODELS[model_key],
            messages=messages,
            temperature=0.3,
            max_completion_tokens=1024,
            top_p=1,
        )

    await bot.send_chat_action(m.chat.id, "typing")
    resp = await asyncio.to_thread(_call)
    reply = resp.choices[0].message.content

    await m.answer(reply)

    blocks = extract_code_blocks(reply)
    await state.update_data(last_reply=reply, last_code_blocks=blocks)


# ===========================
# üî• –û—Å–Ω–æ–≤–Ω–∏–π –æ–±—Ä–æ–±–Ω–∏–∫ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
# ===========================
@dp.message(Chat.chatting)
async def handle(m: types.Message, state: FSMContext):
    # –Ø–∫—â–æ –º–∏ —á–µ–∫–∞—î–º–æ –∫–æ–¥ –¥–ª—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è
    data = await state.get_data()
    if data.get("awaiting_code_explain"):
        await state.update_data(awaiting_code_explain=False)
        code_text = m.text
        await _explain_code_internal(m, state, code_text)
        return

    await bot.send_chat_action(m.chat.id, "typing")

    history = data.get("history", [])
    model_key = data.get("model_key", DEFAULT_MODEL_KEY)
    answer_mode = data.get("answer_mode", DEFAULT_ANSWER_MODE)
    wrap_code_flag = data.get("wrap_code", True)

    # –æ—á–∏—â–∞—î–º–æ —ñ—Å—Ç–æ—Ä—ñ—é –≤—ñ–¥ —Ç–µ—Ö–Ω—ñ—á–Ω–∏—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ñ–≤ (–Ω–∞ –≤—Å—è–∫–∏–π –≤–∏–ø–∞–¥–æ–∫)
    clean_history = []
    for msg in history:
        if "__CB_" not in msg.get("content", ""):
            clean_history.append(msg)
    history = clean_history

    history.append({"role": "user", "content": m.text})

    style_instruction = ANSWER_MODES.get(answer_mode, "")

    system_msg = {
        "role": "system",
        "content": (
            "–¢–∏ ‚Äî —Ç–µ—Ö–Ω—ñ—á–Ω–∏–π AI-–ø–æ–º—ñ—á–Ω–∏–∫. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é.\n" + style_instruction
        ),
    }

    messages = [system_msg] + history

    def _call():
        return client.chat.completions.create(
            model=MODELS[model_key],
            messages=messages,
            temperature=0.7,
            max_completion_tokens=2048,
            top_p=1,
        )

    resp = await asyncio.to_thread(_call)
    reply = resp.choices[0].message.content

    # –ê–≤—Ç–æ-–æ–±–≥–æ—Ä—Ç–∞–Ω–Ω—è –∫–æ–¥—É (–æ–ø—Ü—ñ–π–Ω–æ)
    if wrap_code_flag:
        reply = wrap_code_blocks(reply)

    await m.answer(reply)

    # –û–Ω–æ–≤–∏–º–æ —ñ—Å—Ç–æ—Ä—ñ—é —Ç–∞ –æ—Å—Ç–∞–Ω–Ω—é –≤—ñ–¥–ø–æ–≤—ñ–¥—å
    history.append({"role": "assistant", "content": reply})
    code_blocks = extract_code_blocks(reply)

    await state.update_data(
        history=history,
        last_reply=reply,
        last_code_blocks=code_blocks,
    )


# ===========================
# RUN
# ===========================
async def main():
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω–æ")
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
